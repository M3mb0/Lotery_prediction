{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df1 = pd.read_csv('lotto_polonia_3.csv', delimiter=';')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.iloc[:-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(['Numer', 'Dzien', 'Miesiac', 'Rok'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[4423:]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "scaler = StandardScaler().fit(df.values)\n",
    "transformed_dataset = scaler.transform(df.values)\n",
    "transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input and output data\n",
    "number_of_rows = df.values.shape[0]\n",
    "window_length = 21\n",
    "number_of_features = df.values.shape[1]\n",
    "X = np.empty([len(transformed_dataset) - window_length, window_length, number_of_features], dtype=float)\n",
    "y = np.empty([len(transformed_dataset) - window_length, number_of_features], dtype=float)\n",
    "\n",
    "for i in range(0, len(transformed_dataset) - window_length):\n",
    "    X[i] = transformed_dataset[i : i + window_length]\n",
    "    y[i] = transformed_dataset[i + window_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_test_split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_test_split], X[train_test_split:]\n",
    "y_train, y_test = y[:train_test_split], y[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=500, kernel_size=3, activation='relu', input_shape=(window_length, number_of_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=500, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=500, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(number_of_features, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.002), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x=X_train, y=y_train, batch_size=100, epochs=150, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "to_predict = df.tail(21)\n",
    "scaled_to_predict = scaler.transform(to_predict.values)\n",
    "y_pred = model.predict(np.array([scaled_to_predict]))\n",
    "print('The predicted numbers in the last lottery game are:', scaler.inverse_transform(y_pred).astype(int)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers1 = np.array([1,9,11,13,22,23,25,31,33,42,45,51,57,59,60,63,65,70,74,77])\n",
    "#[ 3  7 11 15 19 23 27 30 34 38 42 46 50 54 57 61 65 69 73 77]\n",
    "numbers1 = np.array([2,4,6,10,17,23,24,26,30,44,45,50,53,58,61,66,75,78,79,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.intersect1d(scaler.inverse_transform(y_pred).astype(int)[0], numbers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predicted values to get the original scale\n",
    "predicted_numbers = scaler.inverse_transform(y_pred).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability of each predicted number\n",
    "probabilities = []\n",
    "for number in predicted_numbers:\n",
    "    occurrences = df.tail(20)[df.tail(20) == number].count().sum()  # Count the number of times the predicted number has occurred in the next 20 numbers\n",
    "    probability = occurrences / len(df.tail(20)) * 100  # Calculate the probability as a percentage among the next 20 numbers\n",
    "    probabilities.append(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the probabilities so that they add up to 100%\n",
    "probabilities = [p/sum(probabilities)*100 for p in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted numbers and their corresponding probabilities\n",
    "for i in range(len(predicted_numbers)):\n",
    "    print(f\"The predicted number {predicted_numbers[i]} has a probability of {probabilities[i]:.2f}% to be drawn next.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([6, 9, 14, 17, 19, 22, 27, 31, 35, 36, 42, 48, 49, 48, 54, 60, 62, 66, 71, 75])\n",
    "\n",
    "y = np.intersect1d(scaler.inverse_transform(y_pred).astype(int)[0], x)\n",
    "print(y)\n",
    "\n",
    "np.intersect1d(numbers1, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5485b6597707a8772e24468b9fa729ada7e499471fc0cd7e56d1b94e9e4dce56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
